{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"IMDB Dataset.csv\",delimiter = \",\")\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some potential improvements: replace punctuation with an extra space, to split hyphenated words\n",
    "### or e.g. hot/cold into two words. Shouldn't be too important.\n",
    "\n",
    "def formatStrings(df):\n",
    "    newdf = df.copy()\n",
    "    for index, string in enumerate(df[\"review\"]): \n",
    "        tempString = string.replace('<br /><br />', ' ')\n",
    "        tempString = ''.join(c for c in tempString if c.isalpha() or (c == \" \") or (c == \"'\"))\n",
    "        tempString = tempString.lower()\n",
    "        newdf[\"review\"].iloc[index] = tempString\n",
    "    return newdf\n",
    "\n",
    "def splitStrings(df):\n",
    "    newdf = df.copy()\n",
    "    for index, string in enumerate(df[\"review\"]): \n",
    "        newdf[\"review\"].iloc[index] = string.split(\" \")\n",
    "        \n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "formattedDF = formatStrings(df)\n",
    "splitDF = splitStrings(formattedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = splitDF.sample(frac=0.8) \n",
    "test = splitDF.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createWordTotalsDct(df):\n",
    "    newdf = df.copy()\n",
    "    wordTotalsDct = {}\n",
    "    for index, stringList in enumerate(df[\"review\"]): \n",
    "        for string in stringList:\n",
    "            try:\n",
    "                wordTotalsDct[string] +=1\n",
    "            except KeyError:\n",
    "                wordTotalsDct.update({string:1})\n",
    "                \n",
    "    return wordTotalsDct\n",
    "\n",
    "wordTotalsDct = createWordTotalsDct(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genTheta(df, dct):\n",
    "    \n",
    "    keys = dct.keys()\n",
    "    \n",
    "    thetaDct = {key:[0,0] for key in keys}\n",
    "    thetaNumeratorDct = {key:[0,0] for key in keys}\n",
    "    \n",
    "    d = len(dct)\n",
    "    dctList = list(dct)\n",
    "    c = 2\n",
    "\n",
    "    thetaDenominatorSum = np.zeros((c))\n",
    "    \n",
    "    for index, row in df.iterrows(): \n",
    "        sentiment = row[\"sentiment\"]\n",
    "        stringArray = row[\"review\"]\n",
    "        \n",
    "        if sentiment == \"positive\":\n",
    "            y = 1\n",
    "        else:\n",
    "            y = 0\n",
    "        \n",
    "        thetaDenominatorSum[y] += len(stringArray)\n",
    "        \n",
    "        alpha = 0\n",
    "        \n",
    "        for string in stringArray:\n",
    "            if string in keys:\n",
    "                thetaNumeratorDct[string][y] += 1\n",
    "                \n",
    "    for key in keys:\n",
    "        for y in range(0,c):\n",
    "            thetaDct[key][y] = thetaNumeratorDct[key][y]/thetaDenominatorSum[y] # no smoothing\n",
    "            \n",
    "    return thetaDct\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatureDct(row, thetaDct):\n",
    "\n",
    "    keys = thetaDct.keys()\n",
    "    \n",
    "    featureDct = {key:0 for key in keys}\n",
    "    stringArray = row[\"review\"]\n",
    "    \n",
    "    for string in stringArray:\n",
    "        if string in keys:\n",
    "            featureDct[string] += 1\n",
    "        \n",
    "    return featureDct\n",
    "\n",
    "def getMaxProb(featureDct, logThetaDct):\n",
    "    \n",
    "    logProbSums = [0,0]\n",
    "    for key, x_alpha in featureDct.items():\n",
    "        for y in range(0,c):     \n",
    "            logProbSums[y] += x_alpha * logThetaDct[key][y]\n",
    "    \n",
    "    argMaxProb = np.argmax(logProbSums)\n",
    "    \n",
    "    return argMaxProb\n",
    "\n",
    "def testNaiveBayes(test, thetaDct):\n",
    "    \n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    \n",
    "    correctIndices = []\n",
    "    incorrectIndices = []\n",
    "    \n",
    "    logThetaDct = {key:np.log(value) for key, value in thetaDct.items()}\n",
    "    \n",
    "    for index, row in test.iterrows():\n",
    "        \n",
    "        stringSentiment = row[\"sentiment\"]\n",
    "        \n",
    "        if stringSentiment == \"positive\":\n",
    "            trueSentiment = 1\n",
    "        else:\n",
    "            trueSentiment = 0\n",
    "        \n",
    "        featureDct = getFeatureDct(row, thetaDct)\n",
    "        predictedSentiment = getMaxProb(featureDct, logThetaDct)\n",
    "        \n",
    "        if trueSentiment == predictedSentiment:\n",
    "            correct += 1\n",
    "            correctIndices.append(index)\n",
    "        else:\n",
    "            incorrect += 1\n",
    "            incorrectIndices.append(index)\n",
    "    \n",
    "    percScore = 100 * correct / (correct + incorrect)\n",
    "    \n",
    "    return percScore, correctIndices, incorrectIndices\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - taking d most frequently occuring words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating theta!\n",
      "Bag-of-words dimension d = 200 scored 67.0%\n",
      "Bag-of-words dimension d = 500 scored 73.62%\n",
      "Bag-of-words dimension d = 1000 scored 76.87%\n",
      "Bag-of-words dimension d = 2000 scored 80.09%\n",
      "Bag-of-words dimension d = 3000 scored 81.14%\n",
      "Bag-of-words dimension d = 5000 scored 82.16%\n"
     ]
    }
   ],
   "source": [
    "c = 2\n",
    "dList = [200, 500, 1000, 2000, 3000, 5000]\n",
    "\n",
    "scoresList = []\n",
    "correctIndicesList = []\n",
    "incorrectIndicesList = []\n",
    "\n",
    "dct = {key: wordTotalsDct[key] for key in sorted(wordTotalsDct, key=wordTotalsDct.get, reverse=True)[:max(dList)]}\n",
    "thetaDct = genTheta(train, dct)\n",
    "\n",
    "print(\"Finished calculating theta!\")\n",
    "\n",
    "for d in dList:\n",
    "    \n",
    "    truncThetaDct = {key: thetaDct[key] for key in sorted(wordTotalsDct, key=wordTotalsDct.get, reverse=True)[:d]}\n",
    "    percScore, correctIndices, incorrectIndices = testNaiveBayes(test, truncThetaDct)\n",
    "    \n",
    "    scoresList.append(percScore)\n",
    "    correctIndicesList.append(correctIndices)\n",
    "    incorrectIndicesList.append(incorrectIndices)\n",
    "    \n",
    "    print(\"Bag-of-words dimension d = {} scored {}%\".format(d, percScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - taking d \"best\" words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-words dimension d = 50 scored 53.92%\n",
      "Bag-of-words dimension d = 100 scored 60.1%\n",
      "Bag-of-words dimension d = 150 scored 68.59%\n",
      "Bag-of-words dimension d = 200 scored 70.86%\n",
      "Bag-of-words dimension d = 250 scored 74.56%\n",
      "Bag-of-words dimension d = 500 scored 81.26%\n"
     ]
    }
   ],
   "source": [
    "dList = [50,100,150,200,250,500]\n",
    "\n",
    "\n",
    "def featureOptimiser(val):\n",
    "        return max(val[1][1]/val[1][0],val[1][0]/val[1][1])\n",
    "\n",
    "for d in dList:\n",
    "    optimiseThetaDct = sorted(thetaDct.items(), key=featureOptimiser, reverse=True)[:d]\n",
    "    optimisedFeaturesDct = {key: value for key, value in optimiseThetaDct}\n",
    "    \n",
    "    percScore, correctIndices, incorrectIndices = testNaiveBayes(test, optimisedFeaturesDct)\n",
    "    print(\"Bag-of-words dimension d = {} scored {}%\".format(d, percScore))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - taking d \"best\" words that surpass some frequency threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-words dimension d = 50 scored 67.27%\n",
      "Bag-of-words dimension d = 100 scored 77.99%\n",
      "Bag-of-words dimension d = 150 scored 81.19%\n",
      "Bag-of-words dimension d = 200 scored 81.31%\n",
      "Bag-of-words dimension d = 250 scored 81.06%\n",
      "Bag-of-words dimension d = 500 scored 81.38%\n"
     ]
    }
   ],
   "source": [
    "dList = [50,100,150,200,250,500]\n",
    "\n",
    "\n",
    "def featureOptimiser(val):\n",
    "    if max(val[1]) < 1*10**(-4):\n",
    "        return -1\n",
    "    else:\n",
    "        return max(val[1][1]/val[1][0],val[1][0]/val[1][1])\n",
    "\n",
    "for d in dList:\n",
    "    optimiseThetaDct = sorted(thetaDct.items(), key=featureOptimiser, reverse=True)[:d]\n",
    "    optimisedFeaturesDct = {key: value for key, value in optimiseThetaDct}\n",
    "    \n",
    "    percScore, correctIndices, incorrectIndices = testNaiveBayes(test, optimisedFeaturesDct)\n",
    "    print(\"Bag-of-words dimension d = {} scored {}%\".format(d, percScore))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following reviews were classified incorrectly: \n",
      "\n",
      "Correct classification would have been: negative\n",
      "There is not a single sympathetic character in this entire movie. Is it the lawyer played by Kenneth Branagh that we're supposed to be pulling for? Well, let's see -- we learn he's a sleazebag defense attorney who gets criminals off on technicalities. He treats his coworkers like cattle, gets them involved in his own personal crisis (in the process, getting one of them killed), jeopardizes the safety of his kids, threatens his ex-wife's new boyfriend, tries to strong-arm the police and school administrators -- and all this for what? Because he was THINKING WITH HIS LITTLE HEAD! I was really pulling for the father and his gang to beat the stuffing out of the lawyer and drown him in the swamp...it would have made for a far more satisfying ending.\n",
      "\n",
      "\n",
      "Correct classification would have been: positive\n",
      "This picture for me scores very highly as it is a hugely enjoyable and amusing spoof of Alien Invaders taking over a town and many of its' men folk.<br /><br />The town and the players are all decked out in sort of 1950's style and the whole movie has a deliberate tacky and kitschy feel to it. Some of the scenes are hilarious like with the birth of an alien creature.<br /><br />All the actors give full blooded and serious performances which makes the film even funnier and the special effects and Aliens are at least it seems to me intentionally 3rd rate to add to the amusement.<br /><br />These type of films often deserve a cult following:<br /><br />8/10.\n",
      "\n",
      "\n",
      "Correct classification would have been: negative\n",
      "As a big fan of gorilla movies in general, I anticipated that this one would be great - and as for the gorilla effects, They were quite good, however - that is the only thing I can write about this flop. The film claims to be based on a true story but in effect, it does not even come close to what actually happened to \"Buddy\" - who in real life, was the famous Gargantua, sold to Ringling Bros. by our supposed \"heroic\" Gertrude Lintz, known by many animal enthusiasts as a woman who hardly had her animals' welfare in the best interest. As far as Buddy being portrayed as becoming aggressive, this was total fiction and at no time did the gorilla, in real life, resort to such behavior. buddy did, in fact, escape his wooden crate (not a plush cage room as depicted in movie) during a storm, to seek shelter and comfort in the house, which frightened Gertrude Lintz into selling him. No, Buddy was not released into a gorilla family surrounded by lush trees in a zoological paradise - he was abandoned in a wooden crate, deep in the back of a garage for some time with only a single light bulb for comfort and then sold to the circus - where he actually lived a better life having peanuts thrown at him until he died (historically the oldest living gorilla on record, by the way) before a show in Miami. Notice also, in the film, how Buddy grows older but the chimpanzees never age. (The chimps, by the way, were not raised simultaneously with other animals, including Buddy, as portrayed in the film)\n",
      "\n",
      "\n",
      "Correct classification would have been: positive\n",
      "I gave it an 8 only because it had received such low votes... this is definitely really about a 5.5..... Ummm.. it was kind of bloody, had likeable, shallow characters, and it had some really hot babes in it. I like the eclectic killer, because he didn't kill people the same way everytime... that sometimes gets old.\n",
      "\n",
      "\n",
      "Correct classification would have been: positive\n",
      "It has been 16 years since it's original run, I would have hoped by now some \"marketing wizard\" would have promoted a live actor version of this classic by now, or at least sought to re-release the original 65 episodes. I can't fathom why the sci-fi or cartoon network haven't snapped this up. Galaxy Rangers actually had well thought out plots, and even better scripts.The animation was above average quality for it's time, and excellent when compared to the talking slide show Japanese animation of today. It predated the heavy toon-toy tie in market, this may have sealed it's doom too. I would willingly spend cash on a DVD of GR if available.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The following reviews were classified incorrectly: \\n\")\n",
    "\n",
    "for i in range(0,5):\n",
    "    index = incorrectIndicesList[-1][i]\n",
    "    print(\"Correct classification would have been: {}\".format(df[\"sentiment\"].iloc[index]))\n",
    "    \n",
    "    print(df[\"review\"].iloc[index])\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
